WEBVTT
Kind: captions
Language: en

00:00:07.680 --> 00:00:09.280
Hello. This is 6 Minute English

00:00:09.280 --> 00:00:11.000
from BBC Learning English.

00:00:11.000 --> 00:00:11.760
I'm Neil.

00:00:11.760 --> 00:00:13.480
And I'm Rob.

00:00:13.480 --> 00:00:17.640
Now, I'm sure most of us have interacted
with a chatbot.

00:00:17.640 --> 00:00:22.560
These are bits of computer technology
that respond to text with text

00:00:22.560 --> 00:00:24.600
or respond to your voice.

00:00:24.600 --> 00:00:28.000
You ask it a question
and usually it comes up

00:00:28.000 --> 00:00:29.200
with an answer.

00:00:29.200 --> 00:00:31.680
Yes, it's almost like talking
to another human.

00:00:31.680 --> 00:00:33.440
But of course, it's not.

00:00:33.440 --> 00:00:36.080
It's just a clever piece
of technology.

00:00:36.080 --> 00:00:39.800
It's becoming more sophisticated,
more advanced and complex,

00:00:39.800 --> 00:00:43.000
but could they replace
real human interaction altogether?

00:00:43.000 --> 00:00:46.560
We'll discuss that
more in a moment and find out if chatbots

00:00:46.560 --> 00:00:49.680
really think for themselves. But first,

00:00:49.680 --> 00:00:53.680
I have a question for you, Rob. The
first computer program that allowed

00:00:53.680 --> 00:00:58.080
some kind of plausible conversation
between humans and machines

00:00:58.080 --> 00:01:00.920
was invented in 1966.

00:01:00.920 --> 00:01:02.680
But what was it called?

00:01:02.680 --> 00:01:05.040
Was it a) Alexa.

00:01:05.040 --> 00:01:10.080
b) Eliza, or c) Parry?
Well, it's not Alexa,

00:01:10.080 --> 00:01:12.160
that's too new, so I'll guess

00:01:12.160 --> 00:01:13.320
c) Parry.

00:01:13.320 --> 00:01:16.800
I'll reveal the answer
at the end of the programme.

00:01:16.800 --> 00:01:22.200
Now, the old chatbots of the 1960s and 70s
were quite basic.

00:01:22.200 --> 00:01:27.800
But more recently, the technology is
able to predict the next word that is

00:01:27.800 --> 00:01:32.600
likely to be used in a sentence and it
learns words and sentence structures.

00:01:32.600 --> 00:01:33.960
It's clever stuff.

00:01:33.960 --> 00:01:36.720
I've experienced using them
when talking to my bank

00:01:36.720 --> 00:01:40.040
or when I have problems trying
to book a ticket on a website.

00:01:40.040 --> 00:01:42.520
I no longer phone a human,

00:01:42.520 --> 00:01:45.360
I speak to
a virtual assistant instead.

00:01:45.360 --> 00:01:48.240
Probably the most well known chatbot
at the moment

00:01:48.240 --> 00:01:49.880
is ChatGTP.

00:01:49.880 --> 00:01:52.800
It is. The claim is
that it's able to answer

00:01:52.800 --> 00:01:54.480
anything you ask it.

00:01:54.480 --> 00:01:55.760
This includes writing

00:01:55.760 --> 00:01:57.440
students' essays.

00:01:57.440 --> 00:02:00.040
Now, this is something
that was discussed on the BBC

00:02:00.040 --> 00:02:02.560
Radio 4 programme, Word of Mouth.

00:02:02.560 --> 00:02:04.200
Emily M Bender,

00:02:04.200 --> 00:02:07.520
Professor of Computational
Linguistics at the University

00:02:07.520 --> 00:02:11.280
of Washington, explained
why it's dangerous to always trust

00:02:11.280 --> 00:02:13.440
what a chatbot is telling us.

00:02:13.440 --> 00:02:18.720
We tend to react to grammatical,
fluent, coherent seeming text

00:02:18.720 --> 00:02:23.440
as authoritative and reliable
and valuable and

00:02:23.440 --> 00:02:26.120
we need to be on guard against that
because what is coming out of ChatGTP

00:02:26.120 --> 00:02:27.520
is none of that.

00:02:27.520 --> 00:02:31.840
So, Professor Bender says that
well written text, that is coherent -

00:02:31.840 --> 00:02:35.280
that means it's clear,
carefully considered and sensible -

00:02:35.280 --> 00:02:39.520
makes us think what we are reading is
reliable and authoritative.

00:02:39.520 --> 00:02:43.120
So it's respected, accurate
and important sounding.

00:02:43.120 --> 00:02:47.040
Yes, chatbots might appear to write
in this way. But really,

00:02:47.040 --> 00:02:52.080
they are just predicting one word after
another based on what they have learnt.

00:02:52.080 --> 00:02:55.120
We should therefore be on guard - be careful

00:02:55.120 --> 00:02:59.000
and alert about the accuracy
of what we are being told.

00:02:59.000 --> 00:03:03.800
One concern is that chatbots - a form
of artificial intelligence - work

00:03:03.800 --> 00:03:08.440
a bit like a human brain in the way
it can learn and process information.

00:03:08.440 --> 00:03:13.120
They are able to learn from experience.
Something called deep learning.

00:03:13.120 --> 00:03:17.240
A cognitive psychologist and computer
scientist called Geoffrey Hinton,

00:03:17.240 --> 00:03:21.360
recently said he feared that chatbots
could soon overtake the level

00:03:21.360 --> 00:03:26.520
of information that a human brain
holds. That is a bit scary isn't it?

00:03:26.560 --> 00:03:30.560
But for now, chatbots can be useful
for practical information,

00:03:30.560 --> 00:03:33.240
but sometimes
we start to believe they are human

00:03:33.240 --> 00:03:36.160
and we interact with them
in a human like way.

00:03:36.160 --> 00:03:38.680
This can make us believe them
even more.

00:03:38.680 --> 00:03:39.840
Professor Emma Bender,

00:03:39.840 --> 00:03:41.720
speaking on
the BBC's Word of Mouth

00:03:41.720 --> 00:03:45.280
programme, explains
why we might feel like that.

00:03:45.280 --> 00:03:48.440
I think what's going on there is,
the kinds of answers

00:03:48.440 --> 00:03:50.800
you get depend on the questions

00:03:50.800 --> 00:03:54.160
you put in, because it's doing likely
next word, likely next word.

00:03:54.160 --> 00:03:57.520
And so, if as the human interacting
with this machine

00:03:57.520 --> 00:04:01.640
and you start asking questions
about how do you feel, you know, chatbot?

00:04:01.640 --> 00:04:03.760
And, what do you think of this?

00:04:03.760 --> 00:04:04.960
What are your goals?

00:04:04.960 --> 00:04:08.360
You can provoke it to say things
that sound like what a sentient

00:04:08.360 --> 00:04:13.320
entity would say. We are really primed
to imagine a mind behind language

00:04:13.320 --> 00:04:15.160
whenever we encounter language.

00:04:15.160 --> 00:04:17.040
And so we really have to account for that when

00:04:17.040 --> 00:04:19.280
we're making decisions about these.

00:04:19.480 --> 00:04:22.440
So, although a chatbot might sound human,

00:04:22.440 --> 00:04:23.720
we really just ask it

00:04:23.720 --> 00:04:26.440
things to get a reaction.
We provoke it.

00:04:26.440 --> 00:04:28.240
And it answers only with words

00:04:28.240 --> 00:04:30.320
it has learned to use before.

00:04:30.320 --> 00:04:33.280
Not because it has come up
with a clever answer,

00:04:33.280 --> 00:04:38.280
but it does sound like a sentient
entity. Sentient describes a living
&nbsp;

00:04:38.280 --> 00:04:43.160
thing that experiences feelings. As
Professor Bender says we imagine
&nbsp;

00:04:43.160 --> 00:04:47.920
that when something speaks there is a mind
behind it. But sorry Neil,

00:04:47.920 --> 00:04:49.200
they are not your friend.

00:04:49.200 --> 00:04:50.360
They're just machines.

00:04:50.360 --> 00:04:51.600
Yes, it's strange then

00:04:51.600 --> 00:04:56.520
that we sometimes give chatbots names.
Alexa, Siri, and earlier

00:04:56.520 --> 00:05:00.360
I asked you what the name was
for their first ever chatbot?

00:05:00.360 --> 00:05:03.120
And I guessed it was Parry. Was I right?

00:05:03.120 --> 00:05:05.120
You guessed wrong, I'm afraid.

00:05:05.120 --> 00:05:08.960
Parry was an early form of chatbot
from 1972.

00:05:08.960 --> 00:05:11.920
But the correct answer was Eliza.

00:05:11.920 --> 00:05:15.880
It was considered to be the first
chatterbot, as it was called then,

00:05:15.880 --> 00:05:21.360
and was developed by Joseph Weizenbaum
at Massachusetts Institute of Technology.

00:05:21.360 --> 00:05:22.680
Fascinating stuff.

00:05:22.680 --> 00:05:25.160
OK, now let's recap some
of the vocabulary

00:05:25.160 --> 00:05:29.240
we highlighted in this programme,
starting with sophisticated,

00:05:29.240 --> 00:05:33.360
which can describe technology that
is advanced and complex.

00:05:33.360 --> 00:05:37.880
Something that is coherent, is clear
carefully considered and sensible.

00:05:37.880 --> 00:05:42.480
Authoritative means respected
accurate and important sounding.

00:05:42.480 --> 00:05:43.880
When you are on guard

00:05:43.880 --> 00:05:46.280
you must be careful
and alert about something.

00:05:46.280 --> 00:05:50.840
It could be the accuracy of what
you see or hear or just being aware

00:05:50.840 --> 00:05:54.400
of the dangers around you.
To provoke means to do something

00:05:54.400 --> 00:05:56.880
that causes a reaction from someone.

00:05:56.880 --> 00:06:00.720
Sentient describes something
that experiences feelings.

00:06:00.720 --> 00:06:03.400
So it's something
that is living. Once again

00:06:03.400 --> 00:06:05.720
our six minutes are up. Goodbye.

00:06:05.720 --> 00:06:07.240
Bye bye for now.

